{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercizio 1\n",
    "\n",
    "la prima parte di questo esercizio consiste nell'implementare tre misure di similarità basate su WordNet.\n",
    "\n",
    "Per ciascuna di tali misure di similarità, calcolare\n",
    "- gli indici di correlazione di Spearman e\n",
    "- gli indici di correlazione di Pearson fra i risultati ottenuti e quelli ‘target’ presenti nel file annotato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "           Word 1    Word 2  Human (mean)\n0            love       sex          6.77\n1           tiger       cat          7.35\n2           tiger     tiger         10.00\n3            book     paper          7.46\n4        computer  keyboard          7.62\n..            ...       ...           ...\n348        shower     flood          6.03\n349       weather  forecast          8.34\n350      disaster      area          6.25\n351      governor    office          6.34\n352  architecture   century          3.78\n\n[353 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word 1</th>\n      <th>Word 2</th>\n      <th>Human (mean)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>love</td>\n      <td>sex</td>\n      <td>6.77</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tiger</td>\n      <td>cat</td>\n      <td>7.35</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tiger</td>\n      <td>tiger</td>\n      <td>10.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>book</td>\n      <td>paper</td>\n      <td>7.46</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>computer</td>\n      <td>keyboard</td>\n      <td>7.62</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>348</th>\n      <td>shower</td>\n      <td>flood</td>\n      <td>6.03</td>\n    </tr>\n    <tr>\n      <th>349</th>\n      <td>weather</td>\n      <td>forecast</td>\n      <td>8.34</td>\n    </tr>\n    <tr>\n      <th>350</th>\n      <td>disaster</td>\n      <td>area</td>\n      <td>6.25</td>\n    </tr>\n    <tr>\n      <th>351</th>\n      <td>governor</td>\n      <td>office</td>\n      <td>6.34</td>\n    </tr>\n    <tr>\n      <th>352</th>\n      <td>architecture</td>\n      <td>century</td>\n      <td>3.78</td>\n    </tr>\n  </tbody>\n</table>\n<p>353 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet as wn\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "corpus = pd.read_csv('datasets/WordSim353.csv', sep=',', engine='python')\n",
    "\n",
    "corpus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "- Termini vs sensi: sim(w1, w2) = max[sim(c1, c2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from nltk.corpus import wordnet_ic\n",
    "\n",
    "max_depth = max(max(len(hyp_path) for hyp_path in ss.hypernym_paths()) for ss in wn.all_synsets())\n",
    "def get_hyponyms(synset):\n",
    "    hyponyms = set()\n",
    "    for hyponym in synset.hyponyms():\n",
    "        hyponyms |= set(get_hyponyms(hyponym))\n",
    "    return hyponyms | set(synset.hyponyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<bound method Synset.name of Synset('love.n.01')>, <bound method Synset.name of Synset('emotion.n.01')>, <bound method Synset.name of Synset('feeling.n.01')>, <bound method Synset.name of Synset('state.n.02')>, <bound method Synset.name of Synset('attribute.n.02')>, <bound method Synset.name of Synset('abstraction.n.06')>, <bound method Synset.name of Synset('entity.n.01')>]\n",
      "[<bound method Synset.name of Synset('arouse.v.07')>, <bound method Synset.name of Synset('stimulate.v.03')>, <bound method Synset.name of Synset('arouse.v.01')>, <bound method Synset.name of Synset('make.v.03')>]\n"
     ]
    }
   ],
   "source": [
    "syn1 = wn.synset('love.n.01')\n",
    "syn2 = wn.synset('arouse.v.07')\n",
    "\n",
    "for path in syn1.hypernym_paths():\n",
    "    path = list(reversed(path))\n",
    "    print(([synset.name for synset in path]))\n",
    "\n",
    "for path in syn2.hypernym_paths():\n",
    "    path = list(reversed(path))\n",
    "    print(([synset.name for synset in path]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_depth_lcs(syn1,syn2):\n",
    "    paths1 = (syn1.hypernym_paths())\n",
    "    paths1 = [list(reversed(path)) for path in paths1]\n",
    "    \n",
    "    paths2 = syn2.hypernym_paths()\n",
    "    paths2 = [list(reversed(path)) for path in paths2]\n",
    "\n",
    "    best_index_lcs = max_depth\n",
    "    best_syn_lcs = None\n",
    "    best_depth_lcs = 0\n",
    "\n",
    "    for (path1, path2) in list(product(paths1, paths2)):\n",
    "        index_lcs = -1\n",
    "        depth_lcs = 0\n",
    "\n",
    "        i = 0\n",
    "        while i < len(path1) and index_lcs == -1:\n",
    "            if path1[i] in path2:\n",
    "                index_lcs = path2.index(path1[i])\n",
    "                depth_lcs = len(path2[index_lcs].hypernym_paths()[0])\n",
    "            i = i + 1\n",
    "\n",
    "        if index_lcs != -1 and depth_lcs > best_depth_lcs:\n",
    "            best_index_lcs = index_lcs\n",
    "            best_syn_lcs = path2[best_index_lcs]\n",
    "            best_depth_lcs = depth_lcs\n",
    "\n",
    "    #brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "    #print('atteso: ', syn1.lowest_common_hypernyms(syn2 ,brown_ic)[0])\n",
    "    #print('trovato: ', best_syn_lcs)\n",
    "\n",
    "    return len(sorted(best_syn_lcs.hypernym_paths(), key=len)[0]) if (best_depth_lcs != 0) else 0\n",
    "\n",
    "\n",
    "get_depth_lcs(syn1, syn2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "correct = True\n",
    "for (syn1,syn2) in list(product(wn.all_synsets(),wn.all_synsets())):\n",
    "    correct = (get_depth_lcs(syn1, syn2) in syn1.lowest_common_hypernyms(syn2)) & correct\n",
    "    if syn1.shortest_path_distance(syn2) == get_depth_lcs(syn1, syn2):\n",
    "        print('senso 1: ', syn1, ' senso 2: ',syn2)\n",
    "print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_shortest_distance(syn1,syn2):\n",
    "    paths1 = (syn1.hypernym_paths())\n",
    "    paths1 = [list(reversed(path)) for path in paths1]\n",
    "    \n",
    "    paths2 = syn2.hypernym_paths()\n",
    "    paths2 = [list(reversed(path)) for path in paths2]\n",
    "\n",
    "    best_syn_distance = max_depth * 2\n",
    "\n",
    "    for (path1, path2) in list(product(paths1, paths2)):\n",
    "        index_lcs = -1\n",
    "        syn_distance = max_depth * 2\n",
    "\n",
    "        i = 0\n",
    "        while i < len(path1) and index_lcs == -1:\n",
    "            if path1[i] in path2:\n",
    "                index_lcs = path2.index(path1[i])\n",
    "                syn_distance = index_lcs + i\n",
    "            i = i + 1\n",
    "\n",
    "        if (index_lcs != -1 and syn_distance < best_syn_distance):\n",
    "            best_syn_distance = syn_distance\n",
    "\n",
    "    \n",
    "    return best_syn_distance\n",
    "\n",
    "print('atteso: ', syn1.shortest_path_distance(syn2))\n",
    "print('trovato: ', get_shortest_distance(syn1, syn2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "correct = True\n",
    "for (syn1,syn2) in list(product(wn.all_synsets(),wn.all_synsets())):\n",
    "    correct = syn1.shortest_path_distance(syn2) == get_shortest_distance(syn1, syn2) & correct\n",
    "    if not syn1.shortest_path_distance(syn2) == get_shortest_distance(syn1, syn2):\n",
    "        print('senso 1: ', syn1, ' senso 2: ',syn2)\n",
    "print(correct)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wu-Palmer metric\n",
    "\n",
    "cs(s1, s2) = 2 · depth(LCS) / depth(s1) + depth(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def wup_similarity(syn1,syn2):\n",
    "    depth_lcs = get_depth_lcs(syn1, syn2)\n",
    "    depth_syn1 = len(sorted(syn1.hypernym_paths(), key=len)[0])\n",
    "    depth_syn2 = len(sorted(syn2.hypernym_paths(), key=len)[0])\n",
    "\n",
    "    return ((2 * depth_lcs) / (depth_syn1 + depth_syn2)) * 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shortest path metric\n",
    "\n",
    "simpath(s1, s2)=2 · depthMax - len(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def sp_similarity(syn1,syn2):\n",
    "    shortest_distance = get_shortest_distance(syn1, syn2)\n",
    "\n",
    "    return (2 * max_depth - shortest_distance) / (2 * max_depth) * 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leakcock & Chodorow metric\n",
    "\n",
    "simLC (s1, s2) =  log (len(s1, s2) / 2 · depthMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def lch_similarity(syn1,syn2):\n",
    "    distance = get_shortest_distance(syn1, syn2)\n",
    "    return -math.log((distance) / (2.0 * max_depth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "token1 = 'love'\n",
    "token2 = 'sex'\n",
    "\n",
    "syns1 = wn.synsets(token1)\n",
    "syns2 = wn.synsets(token2)\n",
    "\n",
    "best_similarity = 0\n",
    "best_syn1 = None\n",
    "best_syn2 = None\n",
    "\n",
    "for (syn1, syn2) in list(product(syns1, syns2)):\n",
    "    similarity = sp_similarity(syn1, syn2)\n",
    "\n",
    "    print('syn1: ', syn1)\n",
    "    print('syn2: ', syn2)\n",
    "    print('atteso: ', syn1.path_similarity(syn2) * 10)\n",
    "    print('trovato: ', similarity)\n",
    "    print('----------------')\n",
    "\n",
    "    if similarity != None and similarity > best_similarity:\n",
    "        best_similarity = similarity\n",
    "        best_syn1 = syn1\n",
    "        best_syn2 = syn2\n",
    "\n",
    "print('token1: ', token1)\n",
    "print('token2: ', token2)\n",
    "print('atteso: ', row[1]['Human (mean)'])\n",
    "print('atteso: 6.77')\n",
    "print('trovato: ', best_similarity)\n",
    "print('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_similarity(metric):\n",
    "    for row in corpus.iterrows():\n",
    "        token1 = row[1]['Word 1']\n",
    "        token2 = row[1]['Word 2']\n",
    "\n",
    "        syns1 = wn.synsets(token1)\n",
    "        syns2 = wn.synsets(token2)\n",
    "\n",
    "        best_similarity = 0\n",
    "        best_syn1 = None\n",
    "        best_syn2 = None\n",
    "\n",
    "        for (syn1, syn2) in list(product(syns1, syns2)):\n",
    "            if metric == 'wup_similarity':\n",
    "                similarity = wup_similarity(syn1, syn2)\n",
    "            elif metric == 'sp_similarity':\n",
    "                similarity = sp_similarity(syn1, syn2)\n",
    "            \n",
    "            if similarity != None and similarity > best_similarity:\n",
    "                best_similarity = similarity\n",
    "                best_syn1 = syn1\n",
    "                best_syn2 = syn2\n",
    "\n",
    "        print('token1: ', token1)\n",
    "        print('token2: ', token2)\n",
    "        print('ipotizzato: ', row[1]['Human (mean)'])\n",
    "        print('calcolato: ', best_similarity)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "compute_similarity('wup_similarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "compute_similarity('sp_similarity')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
