{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercizio 1\n",
    "\n",
    "la prima parte di questo esercizio consiste nell'implementare tre misure di similarità basate su WordNet.\n",
    "\n",
    "Per ciascuna di tali misure di similarità, calcolare\n",
    "- gli indici di correlazione di Spearman e\n",
    "- gli indici di correlazione di Pearson fra i risultati ottenuti e quelli ‘target’ presenti nel file annotato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Human (mean)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>sex</td>\n",
       "      <td>6.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tiger</td>\n",
       "      <td>cat</td>\n",
       "      <td>7.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tiger</td>\n",
       "      <td>tiger</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book</td>\n",
       "      <td>paper</td>\n",
       "      <td>7.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>computer</td>\n",
       "      <td>keyboard</td>\n",
       "      <td>7.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>shower</td>\n",
       "      <td>flood</td>\n",
       "      <td>6.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>weather</td>\n",
       "      <td>forecast</td>\n",
       "      <td>8.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>disaster</td>\n",
       "      <td>area</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>governor</td>\n",
       "      <td>office</td>\n",
       "      <td>6.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>architecture</td>\n",
       "      <td>century</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word 1    Word 2  Human (mean)\n",
       "0            love       sex          6.77\n",
       "1           tiger       cat          7.35\n",
       "2           tiger     tiger         10.00\n",
       "3            book     paper          7.46\n",
       "4        computer  keyboard          7.62\n",
       "..            ...       ...           ...\n",
       "348        shower     flood          6.03\n",
       "349       weather  forecast          8.34\n",
       "350      disaster      area          6.25\n",
       "351      governor    office          6.34\n",
       "352  architecture   century          3.78\n",
       "\n",
       "[353 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet as wn\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "corpus = pd.read_csv('datasets/WordSim353.csv', sep=',', engine='python')\n",
    "\n",
    "corpus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "- Termini vs sensi: sim(w1, w2) = max[sim(c1, c2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from nltk.corpus import wordnet_ic\n",
    "\n",
    "max_depth = max(max(len(hyp_path) for hyp_path in ss.hypernym_paths()) for ss in wn.all_synsets())\n",
    "def get_hyponyms(synset):\n",
    "    hyponyms = set()\n",
    "    for hyponym in synset.hyponyms():\n",
    "        hyponyms |= set(get_hyponyms(hyponym))\n",
    "    return hyponyms | set(synset.hyponyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn1 = wn.synset('cat.n.01')\n",
    "syn2 = wn.synset('mouse.n.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atteso:  [Synset('placental.n.01')]\n",
      "trovato:  Synset('placental.n.01')\n"
     ]
    }
   ],
   "source": [
    "def depth_lcs(syn1,syn2):\n",
    "    paths1 = (syn1.hypernym_paths())\n",
    "    paths1 = [list(reversed(path)) for path in paths1]\n",
    "    \n",
    "    paths2 = syn2.hypernym_paths()\n",
    "    paths2 = [list(reversed(path)) for path in paths2]\n",
    "\n",
    "    best_index_lcs = max_depth\n",
    "    best_syn_lcs = None\n",
    "    best_depth_lcs = 0\n",
    "\n",
    "    for (path1, path2) in list(product(paths1, paths2)):\n",
    "        index_lcs = -1\n",
    "        depth_lcs = 0\n",
    "\n",
    "        i = 0\n",
    "        while i < len(path1) and index_lcs == -1:\n",
    "            if path1[i] in path2:\n",
    "                index_lcs = path2.index(path1[i])\n",
    "                depth_lcs = len(path2[index_lcs].hypernym_paths()[0])\n",
    "            i = i + 1\n",
    "\n",
    "        if (index_lcs != -1 and depth_lcs > best_depth_lcs):\n",
    "            best_index_lcs = index_lcs\n",
    "            best_syn_lcs = path2[best_index_lcs]\n",
    "            best_depth_lcs = depth_lcs\n",
    "    \n",
    "    return best_syn_lcs\n",
    "    \n",
    "\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "print('atteso: ', syn1.lowest_common_hypernyms(syn2 ,brown_ic))\n",
    "print('trovato: ', depth_lcs(syn1, syn2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atteso:  5\n",
      "trovato:  5\n"
     ]
    }
   ],
   "source": [
    "def length_syn1_syn2(syn1,syn2):\n",
    "    paths1 = (syn1.hypernym_paths())\n",
    "    paths1 = [list(reversed(path)) for path in paths1]\n",
    "    \n",
    "    paths2 = syn2.hypernym_paths()\n",
    "    paths2 = [list(reversed(path)) for path in paths2]\n",
    "\n",
    "    best_syn_distance = max_depth * 2\n",
    "\n",
    "    for (path1, path2) in list(product(paths1, paths2)):\n",
    "        index_lcs = -1\n",
    "        syn_distance = max_depth * 2\n",
    "\n",
    "        i = 0\n",
    "        while i < len(path1) and index_lcs == -1:\n",
    "            if path1[i] in path2:\n",
    "                index_lcs = path2.index(path1[i])\n",
    "                syn_distance = index_lcs + i\n",
    "            i = i + 1\n",
    "\n",
    "        if (index_lcs != -1 and syn_distance < best_syn_distance):\n",
    "            best_syn_distance = syn_distance\n",
    "\n",
    "    \n",
    "    return best_syn_distance\n",
    "\n",
    "print('atteso: ', syn1.shortest_path_distance(syn2))\n",
    "print('trovato: ', length_syn1_syn2(syn1, syn2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('appointment_book.n.01'), Synset('authority.n.07'), Synset('bestiary.n.01'), Synset('booklet.n.01'), Synset('catalog.n.01'), Synset('catechism.n.02'), Synset('copybook.n.01'), Synset('curiosa.n.01'), Synset('formulary.n.01'), Synset('phrase_book.n.01'), Synset('playbook.n.02'), Synset('pop-up_book.n.01'), Synset('prayer_book.n.01'), Synset('reference_book.n.01'), Synset('review_copy.n.01'), Synset('songbook.n.01'), Synset('storybook.n.01'), Synset('textbook.n.01'), Synset('tome.n.01'), Synset('trade_book.n.01'), Synset('workbook.n.01'), Synset('yearbook.n.01')]\n",
      "[<bound method Synset.name of Synset('book.n.01')>, <bound method Synset.name of Synset('publication.n.01')>, <bound method Synset.name of Synset('work.n.02')>, <bound method Synset.name of Synset('product.n.02')>, <bound method Synset.name of Synset('creation.n.02')>, <bound method Synset.name of Synset('artifact.n.01')>, <bound method Synset.name of Synset('whole.n.02')>, <bound method Synset.name of Synset('object.n.01')>, <bound method Synset.name of Synset('physical_entity.n.01')>, <bound method Synset.name of Synset('entity.n.01')>]\n"
     ]
    }
   ],
   "source": [
    "print(syn1.hyponyms())\n",
    "paths = syn1.hypernym_paths()\n",
    "\n",
    "for path in paths:\n",
    "    path = list(reversed(path))\n",
    "    print(([synset.name for synset in path]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('motor_vehicle.n.01')]\n",
      "[<bound method Synset.name of Synset('car.n.01')>, <bound method Synset.name of Synset('motor_vehicle.n.01')>, <bound method Synset.name of Synset('self-propelled_vehicle.n.01')>, <bound method Synset.name of Synset('wheeled_vehicle.n.01')>, <bound method Synset.name of Synset('container.n.01')>, <bound method Synset.name of Synset('instrumentality.n.03')>, <bound method Synset.name of Synset('artifact.n.01')>, <bound method Synset.name of Synset('whole.n.02')>, <bound method Synset.name of Synset('object.n.01')>, <bound method Synset.name of Synset('physical_entity.n.01')>, <bound method Synset.name of Synset('entity.n.01')>]\n",
      "[<bound method Synset.name of Synset('car.n.01')>, <bound method Synset.name of Synset('motor_vehicle.n.01')>, <bound method Synset.name of Synset('self-propelled_vehicle.n.01')>, <bound method Synset.name of Synset('wheeled_vehicle.n.01')>, <bound method Synset.name of Synset('vehicle.n.01')>, <bound method Synset.name of Synset('conveyance.n.03')>, <bound method Synset.name of Synset('instrumentality.n.03')>, <bound method Synset.name of Synset('artifact.n.01')>, <bound method Synset.name of Synset('whole.n.02')>, <bound method Synset.name of Synset('object.n.01')>, <bound method Synset.name of Synset('physical_entity.n.01')>, <bound method Synset.name of Synset('entity.n.01')>]\n"
     ]
    }
   ],
   "source": [
    "print(syn2.hypernyms())\n",
    "paths = syn2.hypernym_paths()\n",
    "\n",
    "for path in paths:\n",
    "    path = list(reversed(path))\n",
    "    print(([synset.name for synset in path]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wu-Palmer metric\n",
    "\n",
    "cs(s1, s2) = 2 · depth(LCS) / depth(s1) + depth(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('emotion.n.01')]\n"
     ]
    }
   ],
   "source": [
    "#get first row of corpus\n",
    "token1 = corpus.iloc[0]['Word 1']\n",
    "toekn2 = corpus.iloc[0]['Word 2']\n",
    "\n",
    "\n",
    "#get one synset for token1\n",
    "synset1 = wn.synsets(token1)[0]\n",
    "\n",
    "\n",
    "hypernyms1 = synset1.hypernyms()[0]\n",
    "print(hypernyms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypernyms2 = []\n",
    "for hypernym in hypernyms1:\n",
    "    hypernyms2.extend(hypernym.hypernyms())\n",
    "print(hypernyms2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('love.n.01') a strong positive emotion of regard and affection\n",
      "depth:  7\n",
      "Synset('love.n.02') any object of warm affection or devotion\n",
      "depth:  7\n",
      "Synset('beloved.n.01') a beloved person; used as terms of endearment\n",
      "depth:  6\n",
      "Synset('love.n.04') a deep feeling of sexual desire and attraction\n",
      "depth:  8\n",
      "Synset('love.n.05') a score of zero in tennis or squash\n",
      "depth:  7\n",
      "Synset('sexual_love.n.02') sexual activities (often including sexual intercourse) between two people\n",
      "depth:  7\n",
      "Synset('love.v.01') have a great affection or liking for\n",
      "depth:  1\n",
      "Synset('love.v.02') get pleasure from\n",
      "depth:  2\n",
      "Synset('love.v.03') be enamored or in love with\n",
      "depth:  2\n",
      "Synset('sleep_together.v.01') have sexual intercourse with\n",
      "depth:  4\n",
      "\n",
      "\n",
      "Synset('sexual_activity.n.01') activities associated with sexual intercourse\n",
      "depth:  6\n",
      "Synset('sex.n.02') either of the two categories (male or female) into which most organisms are divided\n",
      "depth:  6\n",
      "Synset('sex.n.03') all of the feelings resulting from the urge to gratify sexual impulses\n",
      "depth:  6\n",
      "Synset('sex.n.04') the properties that distinguish organisms on the basis of their reproductive roles\n",
      "depth:  7\n",
      "Synset('arouse.v.07') stimulate sexually\n",
      "depth:  4\n",
      "Synset('sex.v.02') tell the sex (of young chickens)\n",
      "depth:  4\n"
     ]
    }
   ],
   "source": [
    "for ss in wn.synsets(token1):\n",
    "    print(ss, ss.definition())\n",
    "    print('depth: ', len(ss.hypernym_paths()[0]))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "for ss in wn.synsets(toekn2):\n",
    "    print(ss, ss.definition())\n",
    "    print('depth: ', len(ss.hypernym_paths()[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shortest path metric\n",
    "\n",
    "simpath(s1, s2)=2 · depthMax - len(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leakcock & Chodorow metric\n",
    "\n",
    "simLC (s1, s2) =  log (len(s1, s2) / 2 · depthMax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
