{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercizio 2\n",
    "\n",
    "Implementare l’algoritmo di Lesk (!= usare implementazione esistente, e.g., in nltk…).\n",
    "- Estrarre 50 frasi dal corpus SemCor (corpus annotato con i synset di WN) e disambiguare (almeno) un sostantivo per frase. Calcolare l’accuratezza del sistema implementato sulla base dei sensi annotati in SemCor (SemCor è disponibile all’URL http://web.eecs.umich.edu/~mihalcea/downloads.html)\n",
    "- Randomizzare la selezione delle 50 frasi e la selezione del termine da disambiguare, e restituire l’accuratezza media su (per esempio) 10 esecuzioni del programma\n",
    "\n",
    "Opzionale: implementare corpus_lesk_algorithm utilizando semCor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "#nltk.('sedownloadmcor')\n",
    "from nltk.corpus import semcor\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', 'Atlanta', \"'s\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term', 'end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show semcore\n",
    "semcor.sents()[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['The'], Tree(Lemma('group.n.01.group'), [Tree('NE', ['Fulton', 'County', 'Grand', 'Jury'])]), Tree(Lemma('state.v.01.say'), ['said']), Tree(Lemma('friday.n.01.Friday'), ['Friday']), ['an'], Tree(Lemma('probe.n.01.investigation'), ['investigation']), ['of'], Tree(Lemma('atlanta.n.01.Atlanta'), ['Atlanta']), [\"'s\"], Tree(Lemma('late.s.03.recent'), ['recent']), Tree(Lemma('primary.n.01.primary_election'), ['primary', 'election']), Tree(Lemma('produce.v.04.produce'), ['produced']), ['``'], ['no'], Tree(Lemma('evidence.n.01.evidence'), ['evidence']), [\"''\"], ['that'], ['any'], Tree(Lemma('abnormality.n.04.irregularity'), ['irregularities']), Tree(Lemma('happen.v.01.take_place'), ['took', 'place']), ['.']], [['The'], Tree(Lemma('jury.n.01.jury'), ['jury']), Tree(Lemma('far.r.02.far'), ['further']), Tree(Lemma('state.v.01.say'), ['said']), ['in'], Tree(Lemma('term.n.02.term'), ['term']), Tree(Lemma('end.n.02.end'), ['end']), Tree(Lemma('presentment.n.01.presentment'), ['presentments']), ['that'], ['the'], Tree(Lemma('group.n.01.group'), [Tree('NE', ['City', 'Executive', 'Committee'])]), [','], ['which'], Tree(Lemma('own.v.01.have'), ['had']), Tree(Lemma('overall.s.02.overall'), ['over-all']), Tree(Lemma('mission.n.03.charge'), ['charge']), ['of'], ['the'], Tree(Lemma('election.n.01.election'), ['election']), [','], ['``'], Tree(Lemma('deserve.v.01.deserve'), ['deserves']), ['the'], Tree(Lemma('praise.n.01.praise'), ['praise']), ['and'], Tree(Lemma('thanks.n.01.thanks'), ['thanks']), ['of'], ['the'], Tree(Lemma('location.n.01.location'), [Tree('NE', ['City', 'of', 'Atlanta'])]), [\"''\"], ['for'], ['the'], Tree(Lemma('manner.n.01.manner'), ['manner']), ['in'], ['which'], ['the'], Tree(Lemma('election.n.01.election'), ['election']), ['was'], Tree(Lemma('conduct.v.01.conduct'), ['conducted']), ['.']], ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semcor.tagged_sents(tag = 'sem')[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_list(sent):\n",
    "    return [l.label() if isinstance(l, nltk.tree.Tree) else None for l in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimplifiedLesk(word, sentence):\n",
    "    best_sense = wn.synsets(word)[0] if len(wn.synsets(word)) > 0 else None\n",
    "    max_overlap = 0\n",
    "    context = set(sentence)\n",
    "    \n",
    "    for sense in wn.synsets(word):\n",
    "        signature = set(sense.definition().split()).union(set(sense.examples()))\n",
    "        overlap = len(context.intersection(signature))\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            best_sense = sense\n",
    "    \n",
    "    return best_sense\n",
    "\n",
    "def corpus_lesk(corpus):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for sent in corpus.tagged_sents(tag='sem'):\n",
    "        sentence = lemma_list(sent)\n",
    "        for i, (word, tag) in enumerate(sent):\n",
    "            if tag is not None and word not in stop_words:\n",
    "                total += 1\n",
    "                if SimplifiedLesk(word, sentence) == sent[i].label():\n",
    "                    correct += 1\n",
    "    \n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filed\n",
      "Synset('file.v.05')\n",
      "[Lemma('file.v.01.file')]\n",
      "-----------------\n",
      "Many\n",
      "Synset('many.a.01')\n",
      "[Lemma('many.a.01.many')]\n",
      "-----------------\n",
      "possible\n",
      "Synset('possible.a.01')\n",
      "[Lemma('potential.a.01.possible')]\n",
      "-----------------\n",
      "issue\n",
      "Synset('issue.n.04')\n",
      "[Lemma('issue.n.01.issue')]\n",
      "-----------------\n",
      "new\n",
      "Synset('fresh.s.04')\n",
      "[Lemma('new.a.01.new')]\n",
      "-----------------\n",
      "witnesses\n",
      "Synset('spectator.n.01')\n",
      "[Lemma('witness.n.01.witness')]\n",
      "-----------------\n",
      "taxpayers\n",
      "Synset('taxpayer.n.01')\n",
      "[Lemma('taxpayer.n.01.taxpayer')]\n",
      "-----------------\n",
      "funds\n",
      "Synset('funds.n.01')\n",
      "[Lemma('fund.n.01.fund')]\n",
      "-----------------\n",
      "traditional\n",
      "Synset('traditional.s.02')\n",
      "[Lemma('traditional.a.01.traditional')]\n",
      "-----------------\n",
      "Texas\n",
      "Synset('texas.n.01')\n",
      "[Lemma('texas.n.01.Texas')]\n",
      "-----------------\n",
      "Senate\n",
      "Synset('united_states_senate.n.01')\n",
      "[Lemma('senate.n.01.senate')]\n",
      "-----------------\n",
      "went\n",
      "Synset('go.v.10')\n",
      "[Lemma('go.v.02.go')]\n",
      "-----------------\n",
      "This\n",
      "None\n",
      "[None]\n",
      "-----------------\n",
      "items\n",
      "Synset('item.n.01')\n",
      "[Lemma('detail.n.01.item')]\n",
      "-----------------\n",
      "reduce\n",
      "Synset('deoxidize.v.01')\n",
      "[Lemma('reduce.v.01.reduce')]\n",
      "-----------------\n",
      "amicable\n",
      "Synset('amicable.a.01')\n",
      "[Lemma('amicable.a.01.amicable')]\n",
      "-----------------\n",
      "jury\n",
      "Synset('jury.n.01')\n",
      "[Lemma('jury.n.01.jury')]\n",
      "-----------------\n",
      "fair\n",
      "Synset('carnival.n.03')\n",
      "['fair.a.00']\n",
      "-----------------\n",
      "man\n",
      "Synset('man.n.06')\n",
      "[Lemma('marriage.n.02.man_and_wife')]\n",
      "-----------------\n",
      "city\n",
      "Synset('city.n.03')\n",
      "[Lemma('city.n.02.city')]\n",
      "-----------------\n",
      "Blue\n",
      "Synset('blue.s.01')\n",
      "[Lemma('location.n.01.location')]\n",
      "-----------------\n",
      "resolution\n",
      "Synset('resolving_power.n.01')\n",
      "[Lemma('resolution.n.01.resolution')]\n",
      "-----------------\n",
      "reports\n",
      "Synset('report.n.01')\n",
      "[Lemma('report.n.03.report')]\n",
      "-----------------\n",
      "none\n",
      "Synset('none.n.01')\n",
      "[None]\n",
      "-----------------\n",
      "asked\n",
      "Synset('ask.v.02')\n",
      "[Lemma('ask.v.01.ask')]\n",
      "-----------------\n",
      "State\n",
      "Synset('state.n.02')\n",
      "[Lemma('group.n.01.group')]\n",
      "-----------------\n",
      "accepted\n",
      "Synset('bear.v.06')\n",
      "['accepted.s.00']\n",
      "-----------------\n",
      "force\n",
      "Synset('force_out.n.01')\n",
      "[Lemma('coerce.v.01.force')]\n",
      "-----------------\n",
      "phone\n",
      "Synset('telephone.n.01')\n",
      "[Lemma('call.n.01.phone_call')]\n",
      "-----------------\n",
      "Saturday\n",
      "Synset('saturday.n.01')\n",
      "[Lemma('saturday.n.01.Saturday')]\n",
      "-----------------\n",
      "roads\n",
      "Synset('roads.n.01')\n",
      "[Lemma('road.n.01.road')]\n",
      "-----------------\n",
      "bit\n",
      "Synset('bit.n.10')\n",
      "[]\n",
      "-----------------\n",
      "despite\n",
      "Synset('contempt.n.01')\n",
      "[None]\n",
      "-----------------\n",
      "County\n",
      "Synset('county.n.01')\n",
      "[Lemma('location.n.01.location')]\n",
      "-----------------\n",
      "When\n",
      "None\n",
      "[None]\n",
      "-----------------\n",
      "His\n",
      "None\n",
      "[None]\n",
      "-----------------\n",
      "interim\n",
      "Synset('interim.n.01')\n",
      "[Lemma('interim.s.01.interim')]\n",
      "-----------------\n",
      "Highway\n",
      "Synset('highway.n.01')\n",
      "[Lemma('group.n.01.group')]\n",
      "-----------------\n",
      "vote\n",
      "Synset('vote.n.01')\n",
      "[Lemma('vote.n.01.vote')]\n",
      "-----------------\n",
      "policeman\n",
      "Synset('policeman.n.01')\n",
      "[Lemma('policeman.n.01.policeman')]\n",
      "-----------------\n",
      "City\n",
      "Synset('city.n.01')\n",
      "[Lemma('group.n.01.group'), Lemma('location.n.01.location')]\n",
      "-----------------\n",
      "Department\n",
      "Synset('department.n.02')\n",
      "[Lemma('group.n.01.group')]\n",
      "-----------------\n",
      "James\n",
      "Synset('james.n.04')\n",
      "[Lemma('person.n.01.person')]\n",
      "-----------------\n",
      "said\n",
      "Synset('pronounce.v.01')\n",
      "[Lemma('state.v.01.say')]\n",
      "-----------------\n",
      "election\n",
      "Synset('election.n.01')\n",
      "[Lemma('election.n.01.election')]\n",
      "-----------------\n",
      "receive\n",
      "Synset('receive.v.12')\n",
      "[Lemma('receive.v.01.receive')]\n",
      "-----------------\n",
      "fees\n",
      "Synset('tip.v.03')\n",
      "[Lemma('fee.n.01.fee')]\n",
      "-----------------\n",
      "Republicans\n",
      "Synset('republican.n.02')\n",
      "[Lemma('republican.n.01.Republican')]\n",
      "-----------------\n",
      "term\n",
      "Synset('term.n.02')\n",
      "[Lemma('tenure.n.01.term_of_office')]\n",
      "-----------------\n",
      "laws\n",
      "Synset('jurisprudence.n.01')\n",
      "[Lemma('law.n.02.law')]\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "#get 50 random sentences from semcor\n",
    "sentences_with_tag = semcor.tagged_sents(tag = 'sem')[:100]\n",
    "sentences = semcor.sents()[:100]\n",
    "\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(sentences_with_tag))\n",
    "indices = indices[:50]\n",
    "\n",
    "my_sentences_with_tag = [sentences_with_tag[i] for i in indices]\n",
    "my_sentences = [sentences[i] for i in indices]\n",
    "\n",
    "#print(my_sentences_with_tag[0])\n",
    "#print(my_sentences[0])\n",
    "\n",
    "for i, sentence in enumerate(my_sentences):\n",
    "    #lowercase\n",
    "    #sentence = [w.lower() for w in sentence]\n",
    "    #remove stop words\n",
    "    sentence_without_stopwords = [w for w in sentence if not w in stop_words]\n",
    "    #remove punctuation\n",
    "    sentence_without_stopwords = [w for w in sentence_without_stopwords if w.isalpha()]\n",
    "    #get random word\n",
    "    random_word = random.choice(sentence_without_stopwords)\n",
    "    index = sentence.index(random_word)\n",
    "\n",
    "    #print(random_word)\n",
    "\n",
    "    actual_synset = []\n",
    "    for j, cell in enumerate(my_sentences_with_tag[i]):\n",
    "        if random_word in cell[0]:\n",
    "            actual_synset.append(cell.label() if isinstance(cell, nltk.tree.Tree) else None)\n",
    "\n",
    "    #run lesk\n",
    "    predicted_synset = SimplifiedLesk(random_word, sentence)\n",
    "    print(random_word)\n",
    "    print(predicted_synset)\n",
    "    print(actual_synset)\n",
    "    print('-----------------')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
