{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercizio 2\n",
    "\n",
    "Implementare l’algoritmo di Lesk (!= usare implementazione esistente, e.g., in nltk…).\n",
    "- Estrarre 50 frasi dal corpus SemCor (corpus annotato con i synset di WN) e disambiguare (almeno) un sostantivo per frase. Calcolare l’accuratezza del sistema implementato sulla base dei sensi annotati in SemCor (SemCor è disponibile all’URL http://web.eecs.umich.edu/~mihalcea/downloads.html)\n",
    "- Randomizzare la selezione delle 50 frasi e la selezione del termine da disambiguare, e restituire l’accuratezza media su (per esempio) 10 esecuzioni del programma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "#nltk.('sedownloadmcor')\n",
    "from nltk.corpus import semcor\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_list(sent):\n",
    "    return [l.label() if isinstance(l, nltk.tree.Tree) else None for l in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimplifiedLesk(word, sentence):\n",
    "    best_sense = wn.synsets(word)[0] if len(wn.synsets(word)) > 0 else None\n",
    "    max_overlap = 0\n",
    "    context = set(sentence)\n",
    "    \n",
    "    for sense in wn.synsets(word):\n",
    "        signature = set(sense.definition().split()).union(set(sense.examples()))\n",
    "        overlap = len(context.intersection(signature))\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            best_sense = sense\n",
    "    \n",
    "    return best_sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mayor\n",
      "Synset('mayor.n.01')\n",
      "[Lemma('person.n.01.person')]\n",
      "-----------------\n",
      "Many\n",
      "Synset('many.a.01')\n",
      "[Lemma('many.a.01.many')]\n",
      "-----------------\n",
      "reports\n",
      "Synset('report.n.02')\n",
      "[Lemma('report.n.03.report')]\n",
      "-----------------\n",
      "million\n",
      "Synset('million.n.01')\n",
      "[Lemma('million.n.01.million')]\n",
      "-----------------\n",
      "Felix\n",
      "None\n",
      "[Lemma('person.n.01.person')]\n",
      "-----------------\n",
      "committee\n",
      "Synset('committee.n.01')\n",
      "[Lemma('committee_member.n.01.committee_member')]\n",
      "-----------------\n",
      "place\n",
      "Synset('topographic_point.n.01')\n",
      "[Lemma('put.v.01.place')]\n",
      "-----------------\n",
      "raises\n",
      "Synset('raise.n.03')\n",
      "[Lemma('raise.n.01.raise')]\n",
      "-----------------\n",
      "visit\n",
      "Synset('visit.n.02')\n",
      "[Lemma('visit.n.01.visit')]\n",
      "-----------------\n",
      "committee\n",
      "Synset('committee.n.01')\n",
      "[Lemma('committee.n.01.committee')]\n",
      "-----------------\n",
      "legislators\n",
      "Synset('legislator.n.01')\n",
      "[Lemma('legislator.n.01.legislator')]\n",
      "-----------------\n",
      "rules\n",
      "Synset('principle.n.01')\n",
      "[Lemma('rule.n.03.rule')]\n",
      "-----------------\n",
      "saw\n",
      "Synset('saw.v.01')\n",
      "[Lemma('witness.v.02.see')]\n",
      "-----------------\n",
      "Fulton\n",
      "Synset('fulton.n.01')\n",
      "[Lemma('location.n.01.location'), Lemma('location.n.01.location')]\n",
      "-----------------\n",
      "reduce\n",
      "Synset('deoxidize.v.01')\n",
      "[Lemma('reduce.v.01.reduce')]\n",
      "-----------------\n",
      "upon\n",
      "None\n",
      "[]\n",
      "-----------------\n",
      "On\n",
      "Synset('on.a.01')\n",
      "[None]\n",
      "-----------------\n",
      "Fulton\n",
      "Synset('fulton.n.01')\n",
      "[Lemma('location.n.01.location')]\n",
      "-----------------\n",
      "said\n",
      "Synset('suppose.v.01')\n",
      "[Lemma('allege.v.01.say')]\n",
      "-----------------\n",
      "personnel\n",
      "Synset('personnel_department.n.01')\n",
      "[Lemma('force.n.04.personnel'), Lemma('force.n.04.personnel')]\n",
      "-----------------\n",
      "force\n",
      "Synset('force_out.n.01')\n",
      "[Lemma('coerce.v.01.force')]\n",
      "-----------------\n",
      "day\n",
      "Synset('sidereal_day.n.01')\n",
      "[Lemma('monday.n.01.Monday'), Lemma('friday.n.01.Friday'), Lemma('day.n.01.day')]\n",
      "-----------------\n",
      "number\n",
      "Synset('phone_number.n.01')\n",
      "[Lemma('number.n.02.number')]\n",
      "-----------------\n",
      "Georgia\n",
      "Synset('georgia.n.02')\n",
      "[Lemma('georgia.n.01.Georgia')]\n",
      "-----------------\n",
      "race\n",
      "Synset('race.n.03')\n",
      "[Lemma('race.n.01.race')]\n",
      "-----------------\n",
      "Garland\n",
      "Synset('wreath.n.01')\n",
      "[Lemma('person.n.01.person')]\n",
      "-----------------\n",
      "accepted\n",
      "Synset('bear.v.06')\n",
      "['accepted.s.00']\n",
      "-----------------\n",
      "violate\n",
      "Synset('desecrate.v.01')\n",
      "[Lemma('transgress.v.01.violate')]\n",
      "-----------------\n",
      "phone\n",
      "Synset('telephone.n.01')\n",
      "[Lemma('call.n.01.phone_call')]\n",
      "-----------------\n",
      "votes\n",
      "Synset('vote.n.01')\n",
      "[Lemma('vote.n.02.vote')]\n",
      "-----------------\n",
      "roads\n",
      "Synset('roads.n.01')\n",
      "[Lemma('road.n.01.road')]\n",
      "-----------------\n",
      "liquor\n",
      "Synset('liquor.n.02')\n",
      "[Lemma('liquor.n.01.liquor')]\n",
      "-----------------\n",
      "protests\n",
      "Synset('protest.n.02')\n",
      "[Lemma('protest.n.01.protest')]\n",
      "-----------------\n",
      "past\n",
      "Synset('past.n.03')\n",
      "[Lemma('past.n.01.past')]\n",
      "-----------------\n",
      "coordinator\n",
      "Synset('coordinator.n.01')\n",
      "[Lemma('coordinator.n.01.coordinator')]\n",
      "-----------------\n",
      "charged\n",
      "Synset('charge.v.01')\n",
      "[Lemma('charge.v.06.charge')]\n",
      "-----------------\n",
      "committee\n",
      "Synset('committee.n.01')\n",
      "[]\n",
      "-----------------\n",
      "Meanwhile\n",
      "Synset('interim.n.01')\n",
      "[Lemma('meanwhile.r.01.meanwhile')]\n",
      "-----------------\n",
      "whether\n",
      "None\n",
      "[None, None]\n",
      "-----------------\n",
      "After\n",
      "Synset('after.r.02')\n",
      "[None]\n",
      "-----------------\n",
      "presentments\n",
      "Synset('presentment.n.01')\n",
      "[Lemma('presentment.n.01.presentment')]\n",
      "-----------------\n",
      "bonds\n",
      "Synset('bond.n.02')\n",
      "[Lemma('bond.n.02.bond')]\n",
      "-----------------\n",
      "rally\n",
      "Synset('rally.n.01')\n",
      "[Lemma('rally.n.01.rally')]\n",
      "-----------------\n",
      "chairman\n",
      "Synset('chair.v.01')\n",
      "[Lemma('president.n.04.chairman')]\n",
      "-----------------\n",
      "inadequate\n",
      "Synset('inadequate.a.01')\n",
      "[Lemma('inadequate.a.01.inadequate')]\n",
      "-----------------\n",
      "funds\n",
      "Synset('funds.n.01')\n",
      "[Lemma('fund.n.01.fund')]\n",
      "-----------------\n",
      "guardians\n",
      "Synset('defender.n.01')\n",
      "[Lemma('defender.n.01.guardian')]\n",
      "-----------------\n",
      "candidate\n",
      "Synset('campaigner.n.01')\n",
      "[Lemma('campaigner.n.01.candidate')]\n",
      "-----------------\n",
      "expires\n",
      "Synset('run_out.v.04')\n",
      "[Lemma('run_out.v.04.expire')]\n",
      "-----------------\n",
      "revised\n",
      "Synset('retool.v.01')\n",
      "[Lemma('revise.v.01.revise')]\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "#get 50 random sentences from semcor\n",
    "sentences_with_tag = semcor.tagged_sents(tag = 'sem')[:100]\n",
    "sentences = semcor.sents()[:100]\n",
    "\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(sentences_with_tag))\n",
    "indices = indices[:50]\n",
    "\n",
    "my_sentences_with_tag = [sentences_with_tag[i] for i in indices]\n",
    "my_sentences = [sentences[i] for i in indices]\n",
    "\n",
    "#print(my_sentences_with_tag[0])\n",
    "#print(my_sentences[0])\n",
    "\n",
    "for i, sentence in enumerate(my_sentences):\n",
    "    #lowercase\n",
    "    #sentence = [w.lower() for w in sentence]\n",
    "    #remove stop words\n",
    "    sentence_without_stopwords = [w for w in sentence if not w in stop_words]\n",
    "    #remove punctuation\n",
    "    sentence_without_stopwords = [w for w in sentence_without_stopwords if w.isalpha()]\n",
    "    #get random word\n",
    "    random_word = random.choice(sentence_without_stopwords)\n",
    "    index = sentence.index(random_word)\n",
    "\n",
    "    #print(random_word)\n",
    "\n",
    "    actual_synset = []\n",
    "    for j, cell in enumerate(my_sentences_with_tag[i]):\n",
    "        if random_word in cell[0]:\n",
    "            actual_synset.append(cell.label() if isinstance(cell, nltk.tree.Tree) else None)\n",
    "\n",
    "    #run lesk\n",
    "    predicted_synset = SimplifiedLesk(random_word, sentence)\n",
    "    print(random_word)\n",
    "    print(predicted_synset)\n",
    "    print(actual_synset)\n",
    "    print('-----------------')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
