{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: annotazione"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frame OLIVERio:\n",
    "[ ] Concessive\n",
    "[ ] History\n",
    "[ ] Change_resistance\n",
    "[ ] Emptying\n",
    "[ ] Performers_and_roles\n",
    "\n",
    "Frame TOMATIS\n",
    "[x] Deciding\n",
    "[x] Intentionally_act\n",
    "[x] Competition\n",
    "[x] Fairness_evaluation\n",
    "[x] Process_continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "definizione frame: A speaker marks a Conceded_state_of_affairs as being or implying a contradiction to the Main_assertion.  Some LUs specify the Main_assertion, others the Conceded_state_of_affairs, as referring to the preceding discourse (i.e. DNI), while yet others are conjunctions joining the two.  'Although she had some trouble , she was able to finish about two hours early .' 'Nevertheless , we did win . DNI ' 'I wanted to come , but I did n't remember where the party was . '\n",
      "\n",
      "\n",
      "frame element (13302): Conceded_state_of_affairs\n",
      "    of Concessive(2150)\n",
      "[definition]\n",
      "  A proposition or set of propositions that the speaker wants the\n",
      "  addressee to believe or take for granted. This statement is not\n",
      "  asserted, but presupposed by the speaker of the sentence, and is\n",
      "  mentioned to contrast with the Main_assertion. It would or could\n",
      "  seem to predict a situation different than the Main_assertion,\n",
      "  but, for reasons left implicit, this normal prediction is\n",
      "  contradicted by the fact that the Main_assertion and the\n",
      "  Conceded_state_of_affairs are both simultaneously true.\n",
      "[abbrev] Msg\n",
      "[coreType] Core\n",
      "[requiresFE] <None>\n",
      "[excludesFE] <None>\n",
      "[semType] \n",
      "  Message(56)\n",
      "\n",
      "Conceded_state_of_affairs :  A proposition or set of propositions that the speaker wants the addressee to believe or take for granted. This statement is not asserted, but presupposed by the speaker of the sentence, and is mentioned to contrast with the Main_assertion. It would or could seem to predict a situation different than the Main_assertion, but, for reasons left implicit, this normal prediction is contradicted by the fact that the Main_assertion and the Conceded_state_of_affairs are both simultaneously true. \n",
      "frame element (13303): Topic\n",
      "    of Concessive(2150)\n",
      "[definition]\n",
      "  An entity which metonymically stands in for an associated\n",
      "  Statement.  'She got married in spite of him .' 'Despite her ,\n",
      "  they finished on time .'\n",
      "[abbrev] Top\n",
      "[coreType] Core\n",
      "[requiresFE] <None>\n",
      "[excludesFE] Conceded_state_of_affairs(13302)\n",
      "[semType] <None>\n",
      "\n",
      "Topic :  An entity which metonymically stands in for an associated Statement.  'She got married in spite of him .' 'Despite her , they finished on time .'\n",
      "frame element (13312): Main_assertion\n",
      "    of Concessive(2150)\n",
      "[definition]\n",
      "  The statement that the speaker wishes to assert or offer as their\n",
      "  main contribution to the discourse, which is be modified or\n",
      "  hedged in some way by the Conceded_state_of_affairs. The force of\n",
      "  the contribution of the Main_assertion is presented as undiluted\n",
      "  by the fact that something different from the Main_assertion\n",
      "  would normally by predicted, based on the facts in the\n",
      "  Conceded_state_of_affairs.\n",
      "[abbrev] \n",
      "[coreType] Core\n",
      "[requiresFE] <None>\n",
      "[excludesFE] <None>\n",
      "[semType] <None>\n",
      "\n",
      "Main_assertion :  The statement that the speaker wishes to assert or offer as their main contribution to the discourse, which is be modified or hedged in some way by the Conceded_state_of_affairs. The force of the contribution of the Main_assertion is presented as undiluted by the fact that something different from the Main_assertion would normally by predicted, based on the facts in the Conceded_state_of_affairs. \n",
      "\n",
      "\n",
      "despite.prep :  FN: in spite of\n",
      "in spite of.prep :  FN: in spite of \n",
      "though.scon :  in spite of the fact that\n",
      "although.scon :  FN: in spite of the fact that\n",
      "while.scon :  when on the other hand\n",
      "if.scon :  FN: with the assumption that there is a possibility that\n",
      "much as.scon :  FN: (usually with verbs of cognition or volition, esp. \"much as I'd like...\") although.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import framenet as fn\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "frame = fn.frame_by_name('Concessive')\n",
    "\n",
    "print('definizione frame:', frame.definition)\n",
    "print('\\n')\n",
    "\n",
    "for fe in frame.FE:\n",
    "    print(fe, ': ', frame.FE[fe].definition)\n",
    "\n",
    "print('\\n')\n",
    "for lu in frame.lexUnit:\n",
    "    print(lu, ': ', frame.lexUnit[lu].definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "lexical unit (256): foresee.v\n\n[definition]\n  COD: be aware of beforehand; predict.\n\n[frame] Expectation(26)\n\n[POS] V\n\n[status] FN1_Sent\n\n[lexemes] foresee/V\n\n[semTypes] 0 semantic types\n\n[URL] https://framenet2.icsi.berkeley.edu/fnReports/data/lu/lu256.xml\n\n[subCorpus] 25 subcorpora\n  V-420-that-sfin, V-430-sfin, V-480-swh, V-570-np-ppfor,\n  V-570-np-ppfrom, V-570-np-ppin, V-570-np-ppon, V-570-np-\n  ppwith, V-620-np-ppother, V-650-np-pother, V-660-trans-\n  simple, V-670-pass-by, V-680-pass, V-690-trans-other,\n  V-730-ppat, V-730-ppfor, V-730-ppfrom, V-730-ppin,\n  V-730-ppon, V-730-ppwith, V-780-ppother, V-810-pother,\n  V-890-intrans-adverb, V-900-other, manually-added\n\n[exemplars] 45 sentences across all subcorpora"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.lu(256)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Synset('deed.n.01')\n",
      "definition: a legal document signed and sealed and delivered to effect a transfer of property and to show the legal right to possess it\n",
      "he signed the deed\n",
      "he kept the title to his car in the glove compartment\n",
      "\n",
      "\n",
      "Synset('act.n.02')\n",
      "definition: something that people do or cause to happen\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n')\n",
    "for syn in wn.synsets('deed'):\n",
    "    print(syn)\n",
    "    print('definition:' , syn.definition())\n",
    "    #print example\n",
    "    for example in syn.examples():\n",
    "        print(example)\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: mapping automatico"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approccio bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import MWETokenizer #tiene conto delle multiword expressions\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import framenet as fn\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "deciding_frame = fn.frame_by_name(\"Deciding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'going', 'im', 'new_york', 'park'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creazione tokenizzatore per le multiword expressions\n",
    "mwes = [x for x in wn.all_lemma_names() if '_' in x]\n",
    "mwes = [tuple(x.split('_')) for x in mwes]\n",
    "tokenizer = MWETokenizer(mwes, separator=' ')\n",
    "\n",
    "def make_set(sentence):\n",
    "    sentence = sentence.lower() #lowercase\n",
    "    sentence = re.sub(r'[^\\w\\s]','',sentence) #remove punctuation\n",
    "    sentence = tokenizer.tokenize(sentence.split()) #tokenize\n",
    "    sentence = [w for w in sentence if not w.isdigit()] #remove numbers\n",
    "    stop_words = set(stopwords.words('english')) #remove stop words\n",
    "    sentence = [w for w in sentence if not w in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer() #lemmatization of definition\n",
    "    sentence = [lemmatizer.lemmatize(w) for w in sentence]\n",
    "\n",
    "    res = []\n",
    "    for w in sentence:\n",
    "        res.append(w.replace(' ', '_'))\n",
    "\n",
    "    return set(res)\n",
    "\n",
    "make_set(\"I'm going to the park of New York.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctx_frame_FN(frame):\n",
    "    name = frame.name\n",
    "    definition = frame.definition\n",
    "    FEs = frame.FE\n",
    "    LUs = frame.lexUnit\n",
    "\n",
    "    sentence = name + ' ' + definition\n",
    "    for fe in FEs:\n",
    "        sentence += ' ' + FEs[fe].definition\n",
    "    for lu in LUs:\n",
    "        sentence += ' ' + LUs[lu].definition\n",
    "\n",
    "    return make_set(sentence)\n",
    "\n",
    "def ctx_frame_element_FN(frame_element):\n",
    "    name = frame_element.name\n",
    "    definition = frame_element.definition\n",
    "    #semtype = frame_element.semType.name\n",
    "\n",
    "    sentence = name + ' ' + definition # + ' ' + semtype\n",
    "   \n",
    "    return make_set(sentence)\n",
    "\n",
    "def ctx_lexical_unit_FN(lexical_unit):\n",
    "    name = lexical_unit.name\n",
    "    definition = lexical_unit.definition.split(':')[1]\n",
    "    exemplars = lexical_unit.exemplars\n",
    "    \n",
    "    sentence = name + ' ' + definition\n",
    "    for ex in exemplars:\n",
    "        sentence += ' ' + ex.annotationSet[0].text\n",
    "\n",
    "    return make_set(sentence)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creazione del contesto (FrameNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_FN = {}\n",
    "\n",
    "#frame\n",
    "ctx_FN[deciding_frame.name.replace(' ', '_')] = ctx_frame_FN(deciding_frame)\n",
    "\n",
    "#FEs\n",
    "for fe in deciding_frame.FE:\n",
    "    ctx_FN[fe.replace(' ', '_')] = ctx_frame_element_FN(deciding_frame.FE[fe])\n",
    "    break\n",
    "\n",
    "#LUs\n",
    "for lu in deciding_frame.lexUnit:\n",
    "    ctx_FN[lu.replace(' ', '_')] = ctx_lexical_unit_FN(deciding_frame.lexUnit[lu])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crezione del contesto (WordNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyponyms(synset):\n",
    "    hyponyms = set()\n",
    "    for hyponym in synset.hyponyms():\n",
    "        hyponyms |= set(get_hyponyms(hyponym))\n",
    "    return hyponyms | set(synset.hyponyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentences(synset, depth=1):\n",
    "    sentence = synset.definition()\n",
    "    for example in synset.examples():\n",
    "        sentence += ' ' + example\n",
    "    for lemma in synset.lemmas():\n",
    "        sentence += ' ' + lemma.name()\n",
    "\n",
    "    if (depth >= 0):\n",
    "        for hypernym in synset.hypernyms():\n",
    "            sentence += ' ' + create_sentences(hypernym, depth-1)\n",
    "        for hyponym in get_hyponyms(synset):\n",
    "            sentence += ' ' + create_sentences(hyponym, depth-1)  \n",
    "\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def ctx_synset_WN(synset):\n",
    "    sentence = create_sentences(synset)\n",
    "    return make_set(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Deciding': Synset('decision_making.n.01'),\n",
       " 'decide.v': Synset('decide.v.02'),\n",
       " 'decision.n': Synset('decision.n.01'),\n",
       " 'rule_out.v': Synset('rule_out.v.02'),\n",
       " 'determine.v': Synset('determine.v.02')}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings = {}\n",
    "for key in ctx_FN:\n",
    "    token = key.split('.')[0]\n",
    "    syns = wn.synsets(token)\n",
    "    max_overlap = 0\n",
    "    for syn in syns:\n",
    "        overlap = len(ctx_synset_WN(syn).intersection(ctx_FN[key])) + 1\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            mappings[key] = syn\n",
    "\n",
    "mappings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approccio grafico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "deciding_frame = fn.frame_by_name(\"Deciding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cognizer\n",
      "Decision\n",
      "Possibilities\n",
      "Time\n",
      "Place\n",
      "Manner\n",
      "Inherent_purpose\n",
      "Circumstance\n",
      "Explanation\n"
     ]
    }
   ],
   "source": [
    "#FEs\n",
    "for fe in deciding_frame.FE: \n",
    "    ctx_FN[fe.replace(' ', '_')] = ctx_frame_element_FN(deciding_frame.FE[fe])\n",
    "#LUs\n",
    "for lu in deciding_frame.lexUnit:\n",
    "    ctx_FN[lu.replace(' ', '_')] = ctx_lexical_unit_FN(deciding_frame.lexUnit[lu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths_between_synsets(synset1, synset2, L=3):\n",
    "    paths = []\n",
    "    visited = set()\n",
    "\n",
    "    def dfs(synset, path):\n",
    "        if synset in visited or len(path) > L:\n",
    "            return\n",
    "        if synset == synset2:\n",
    "            paths.append(path + [synset])\n",
    "            return\n",
    "        visited.add(synset)\n",
    "        for hypernym in synset.hypernyms():\n",
    "            dfs(hypernym, path + [synset])\n",
    "        for hyponym in synset.hyponyms():\n",
    "            dfs(hyponym, path + [synset])\n",
    "\n",
    "    dfs(synset1, [])\n",
    "    return [path for path in paths if len(path) <= L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('decision_making.n.01'), Synset('decide.v.01'), Synset('decide.v.02'), Synset('decide.v.03'), Synset('decide.v.04'), Synset('deciding.s.01')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Synset('decide.v.01')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def score(syn_FN, word_FN, ctx_FN):\n",
    "    ctx_word = ctx_FN[word_FN]\n",
    "\n",
    "    res = 0\n",
    "    for word in ctx_word:\n",
    "        for syn in wn.synsets(word):\n",
    "            #get all connection path between syn and syn_FN\n",
    "            paths = list(get_paths_between_synsets(syn, syn_FN, 3))\n",
    "\n",
    "            for path in paths:\n",
    "                res += np.exp(-len(path)-1)\n",
    "\n",
    "    return res\n",
    "\n",
    "def prob(syn_FN, word_FN, ctx_FN):\n",
    "    sum = 0\n",
    "    for key in ctx_FN:\n",
    "        for syn in wn.synsets(key):\n",
    "            sum += score(syn, key, ctx_FN)\n",
    "\n",
    "    return score(syn_FN, word_FN, ctx_FN) / sum\n",
    "\n",
    "def argmax_prob(word_FN, ctx_FN):\n",
    "    max_prob = 0\n",
    "    max_syn = None\n",
    "    for syn in wn.synsets(word_FN):\n",
    "        prob_syn = prob(syn, word_FN, ctx_FN)\n",
    "        if prob_syn > max_prob:\n",
    "            max_prob = prob_syn\n",
    "            max_syn = syn\n",
    "            \n",
    "    return max_syn\n",
    "\n",
    "print(wn.synsets('deciding'))\n",
    "\n",
    "argmax_prob('Deciding', ctx_FN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: valutazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
