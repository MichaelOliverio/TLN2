{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: annotazione"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frame OLIVERio:\n",
    "[ ] Concessive\n",
    "[ ] History\n",
    "[ ] Change_resistance\n",
    "[ ] Emptying\n",
    "[ ] Performers_and_roles\n",
    "\n",
    "Frame TOMATIS\n",
    "[x] Deciding\n",
    "[ ] Intentionally_act\n",
    "[x] Competition\n",
    "[x] Fairness_evaluation\n",
    "[x] Process_continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "definizione frame: This is an abstract frame for acts performed by sentient beings. It exists mostly for FE inheritance.  'I carried out the deed easily .'\n",
      "\n",
      "\n",
      "Act :  This FE identifies the Act that the Agent performs intentionally.\n",
      "Agent :  The Agent performs the intentional act.  'We have not yet acted .'\n",
      "Place :  This FE identifies the place where the intentional act occurs.\n",
      "Purpose :  This FE identifies the purpose for which an Agent performs an intentional act. John flattered her to receive a raise.\n",
      "Time :  This FE identifies the time when the Agent acts intentionally.\n",
      "Means :  This FE identifies the Means by which an Agent acts intentionally.\n",
      "Manner :  Any description of the intentional act which is not covered by more specific FEs, including secondary effects (quietly, loudly), and general descriptions comparing events (the same way). In addition, it may indicate salient characteristics of an Agent that also affect the action (presumptuously, coldly, deliberately, eagerly, carefully).  ''Twould be best it were done quietly.' \n",
      "Domain :  The Domain within which the Agent acts.  'No doubt he has begun to engage in political activity of late'\n",
      "Frequency :  The Frequency with which the Agent does the Act in a given period of time.\n",
      "Period_of_iterations :  The length of time from when the event denoted by the target began to be repeated to when it stopped.\n",
      "Result :  The Result of an act. \n",
      "Particular_iteration :  Expressions marked with this extra-thematic FE modify a non-iterative use of the target, and indicate that it is conceived as embedded within an iterated series of similar events or states.\n",
      "Explanation :  The Explanation denotes a proposition from which the main clause (headed by the target) logically follows. This often means that the Explanation causes the state of affairs expressed by the target, but not in all cases. \n",
      "Event_description :  This FE gives a description of the Intentionally_act event.\n",
      "Apparent_conclusion :  This FE describes an additional situation or modification that would seem to hold given the rest of the situation. In some cases, it marks a completely separate conclusion than one would draw from the manner of the event in the main clause.  As far as we know, this idea is only explicitly marked in English with \"as if\".  'We have to do our duty as if it matters .'  Usually, the Apparent_conclusion contains another FE, either peripheral or extra-thematic, which is non-factive (i.e., it may, but does not necessarily, hold). For these cases, we annotate the other frame-element on the second layer; thus the following should be annotated with Purpose on the second layer.   'As if to guarantee failure , they conducted the study without consulting experts .' 'As if to guarantee failure , they conducted the study without consulting experts .'  We do not annotate this FE in cases where we merely infer that a part of the sentence is meant sarcastically, as in the following minimal modification of the above sentence:  'To guarantee failure , they conducted the study without consulting experts .'  In this case, we simply annotate the Purpose FE.\n",
      "\n",
      "\n",
      "action.n :  COD: a thing done.\n",
      "do.v :  COD:  perform or carry out (an action).\n",
      "step.n :  COD: a measure or action, especially one of a series taken in order to deal with or achieve a particular thing.\n",
      "act.v :  COD: take action; do something FN: [Usage: normally used only when the Act is implied.]\n",
      "doing.n :  FN: activities \n",
      "activity.n :  COD: an action taken in pursuit of an objective\n",
      "perform.v :  COD: carry out, accomplish, or fulfil (an action, task, or function).\n",
      "carry out.v :  COD: perform (a task or planned operation).\n",
      "conduct.v :  COD: organize and carry out.\n",
      "execute.v :  COD: carry out or put into effect (a plan, order, etc.).\n",
      "engage.v :  COD:  participate or become involved in.\n",
      "measures.n :  COD: a means of achieving a purpose\n",
      "act.n :  COD: a thing done.\n",
      "move.n :  FN: an act embedded with strategy\n",
      "actor.n :  FN: the person deliberately involved in an event or activity\n",
      "agent.n :  FN: A person who acts of his own volition\n",
      "deed.n :  FN: an intentional action\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import framenet as fn\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "frame = fn.frame_by_name('Intentionally_act')\n",
    "\n",
    "print('definizione frame:', frame.definition)\n",
    "print('\\n')\n",
    "\n",
    "for fe in frame.FE:\n",
    "    print(fe, ': ', frame.FE[fe].definition)\n",
    "\n",
    "print('\\n')\n",
    "for lu in frame.lexUnit:\n",
    "    print(lu, ': ', frame.lexUnit[lu].definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Synset('deed.n.01')\n",
      "definition: a legal document signed and sealed and delivered to effect a transfer of property and to show the legal right to possess it\n",
      "he signed the deed\n",
      "he kept the title to his car in the glove compartment\n",
      "\n",
      "\n",
      "Synset('act.n.02')\n",
      "definition: something that people do or cause to happen\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n')\n",
    "for syn in wn.synsets('deed'):\n",
    "    print(syn)\n",
    "    print('definition:' , syn.definition())\n",
    "    #print example\n",
    "    for example in syn.examples():\n",
    "        print(example)\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: mapping automatico"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approccio bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import MWETokenizer #tiene conto delle multiword expressions\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import framenet as fn\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "deciding_frame = fn.frame_by_name(\"Deciding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'going', 'im', 'new_york', 'park'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creazione tokenizzatore per le multiword expressions\n",
    "mwes = [x for x in wn.all_lemma_names() if '_' in x]\n",
    "mwes = [tuple(x.split('_')) for x in mwes]\n",
    "tokenizer = MWETokenizer(mwes, separator=' ')\n",
    "\n",
    "def make_set(sentence):\n",
    "    sentence = sentence.lower() #lowercase\n",
    "    sentence = re.sub(r'[^\\w\\s]','',sentence) #remove punctuation\n",
    "    sentence = tokenizer.tokenize(sentence.split()) #tokenize\n",
    "    sentence = [w for w in sentence if not w.isdigit()] #remove numbers\n",
    "    stop_words = set(stopwords.words('english')) #remove stop words\n",
    "    sentence = [w for w in sentence if not w in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer() #lemmatization of definition\n",
    "    sentence = [lemmatizer.lemmatize(w) for w in sentence]\n",
    "\n",
    "    res = []\n",
    "    for w in sentence:\n",
    "        res.append(w.replace(' ', '_'))\n",
    "\n",
    "    return set(res)\n",
    "\n",
    "make_set(\"I'm going to the park of New York.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctx_frame_FN(frame):\n",
    "    name = frame.name\n",
    "    definition = frame.definition\n",
    "    FEs = frame.FE\n",
    "    LUs = frame.lexUnit\n",
    "\n",
    "    sentence = name + ' ' + definition\n",
    "    for fe in FEs:\n",
    "        sentence += ' ' + FEs[fe].definition\n",
    "    for lu in LUs:\n",
    "        sentence += ' ' + LUs[lu].definition\n",
    "\n",
    "    return make_set(sentence)\n",
    "\n",
    "def ctx_frame_element_FN(frame_element):\n",
    "    name = frame_element.name\n",
    "    definition = frame_element.definition\n",
    "    #semtype = frame_element.semType.name\n",
    "\n",
    "    sentence = name + ' ' + definition # + ' ' + semtype\n",
    "   \n",
    "    return make_set(sentence)\n",
    "\n",
    "def ctx_lexical_unit_FN(lexical_unit):\n",
    "    name = lexical_unit.name\n",
    "    definition = lexical_unit.definition.split(':')[1]\n",
    "    exemplars = lexical_unit.exemplars\n",
    "    \n",
    "    sentence = name + ' ' + definition\n",
    "    for ex in exemplars:\n",
    "        sentence += ' ' + ex.annotationSet[0].text\n",
    "\n",
    "    return make_set(sentence)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creazione del contesto (FrameNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_FN = {}\n",
    "\n",
    "#frame\n",
    "ctx_FN[deciding_frame.name.replace(' ', '_')] = ctx_frame_FN(deciding_frame)\n",
    "\n",
    "#FEs\n",
    "for fe in deciding_frame.FE:\n",
    "    ctx_FN[fe.replace(' ', '_')] = ctx_frame_element_FN(deciding_frame.FE[fe])\n",
    "    break\n",
    "\n",
    "#LUs\n",
    "for lu in deciding_frame.lexUnit:\n",
    "    ctx_FN[lu.replace(' ', '_')] = ctx_lexical_unit_FN(deciding_frame.lexUnit[lu])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crezione del contesto (WordNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyponyms(synset):\n",
    "    hyponyms = set()\n",
    "    for hyponym in synset.hyponyms():\n",
    "        hyponyms |= set(get_hyponyms(hyponym))\n",
    "    return hyponyms | set(synset.hyponyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentences(synset, depth=1):\n",
    "    sentence = synset.definition()\n",
    "    for example in synset.examples():\n",
    "        sentence += ' ' + example\n",
    "    for lemma in synset.lemmas():\n",
    "        sentence += ' ' + lemma.name()\n",
    "\n",
    "    if (depth >= 0):\n",
    "        for hypernym in synset.hypernyms():\n",
    "            sentence += ' ' + create_sentences(hypernym, depth-1)\n",
    "        for hyponym in get_hyponyms(synset):\n",
    "            sentence += ' ' + create_sentences(hyponym, depth-1)  \n",
    "\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def ctx_synset_WN(synset):\n",
    "    sentence = create_sentences(synset)\n",
    "    return make_set(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Deciding': Synset('decision_making.n.01'),\n",
       " 'decide.v': Synset('decide.v.02'),\n",
       " 'decision.n': Synset('decision.n.01'),\n",
       " 'rule_out.v': Synset('rule_out.v.02'),\n",
       " 'determine.v': Synset('determine.v.02')}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings = {}\n",
    "for key in ctx_FN:\n",
    "    token = key.split('.')[0]\n",
    "    syns = wn.synsets(token)\n",
    "    max_overlap = 0\n",
    "    for syn in syns:\n",
    "        overlap = len(ctx_synset_WN(syn).intersection(ctx_FN[key])) + 1\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            mappings[key] = syn\n",
    "\n",
    "mappings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approccio grafico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "deciding_frame = fn.frame_by_name(\"Deciding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cognizer\n",
      "Decision\n",
      "Possibilities\n",
      "Time\n",
      "Place\n",
      "Manner\n",
      "Inherent_purpose\n",
      "Circumstance\n",
      "Explanation\n"
     ]
    }
   ],
   "source": [
    "#FEs\n",
    "for fe in deciding_frame.FE: \n",
    "    ctx_FN[fe.replace(' ', '_')] = ctx_frame_element_FN(deciding_frame.FE[fe])\n",
    "#LUs\n",
    "for lu in deciding_frame.lexUnit:\n",
    "    ctx_FN[lu.replace(' ', '_')] = ctx_lexical_unit_FN(deciding_frame.lexUnit[lu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths_between_synsets(synset1, synset2, L=3):\n",
    "    paths = []\n",
    "    visited = set()\n",
    "\n",
    "    def dfs(synset, path):\n",
    "        if synset in visited or len(path) > L:\n",
    "            return\n",
    "        if synset == synset2:\n",
    "            paths.append(path + [synset])\n",
    "            return\n",
    "        visited.add(synset)\n",
    "        for hypernym in synset.hypernyms():\n",
    "            dfs(hypernym, path + [synset])\n",
    "        for hyponym in synset.hyponyms():\n",
    "            dfs(hyponym, path + [synset])\n",
    "\n",
    "    dfs(synset1, [])\n",
    "    return [path for path in paths if len(path) <= L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('decision_making.n.01'), Synset('decide.v.01'), Synset('decide.v.02'), Synset('decide.v.03'), Synset('decide.v.04'), Synset('deciding.s.01')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Synset('decide.v.01')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def score(syn_FN, word_FN, ctx_FN):\n",
    "    ctx_word = ctx_FN[word_FN]\n",
    "\n",
    "    res = 0\n",
    "    for word in ctx_word:\n",
    "        for syn in wn.synsets(word):\n",
    "            #get all connection path between syn and syn_FN\n",
    "            paths = list(get_paths_between_synsets(syn, syn_FN, 3))\n",
    "\n",
    "            for path in paths:\n",
    "                res += np.exp(-len(path)-1)\n",
    "\n",
    "    return res\n",
    "\n",
    "def prob(syn_FN, word_FN, ctx_FN):\n",
    "    sum = 0\n",
    "    for key in ctx_FN:\n",
    "        for syn in wn.synsets(key):\n",
    "            sum += score(syn, key, ctx_FN)\n",
    "\n",
    "    return score(syn_FN, word_FN, ctx_FN) / sum\n",
    "\n",
    "def argmax_prob(word_FN, ctx_FN):\n",
    "    max_prob = 0\n",
    "    max_syn = None\n",
    "    for syn in wn.synsets(word_FN):\n",
    "        prob_syn = prob(syn, word_FN, ctx_FN)\n",
    "        if prob_syn > max_prob:\n",
    "            max_prob = prob_syn\n",
    "            max_syn = syn\n",
    "            \n",
    "    return max_syn\n",
    "\n",
    "print(wn.synsets('deciding'))\n",
    "\n",
    "argmax_prob('Deciding', ctx_FN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: valutazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
